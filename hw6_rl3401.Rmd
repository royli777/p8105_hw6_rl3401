---
title: "p8105_hw6_rl3401"
author: "Ruoxi Li"
date: "`r Sys.Date()`"
output: github_document
---

## Problem 1
```{r}
library(tidyverse)
library(broom)
library(purrr)
library(ggplot2)
```

Create a city_state variable and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix, AZ; Kansas City, MO and omit Tulsa, AL. Limit the analysis those for whom victim_race is white or black. Be sure that victim_age is numeric.

```{r}
homicide_df_raw = read.csv("data/homicide-data.csv")

homicide_df = homicide_df_raw |>
  mutate(city_state = paste(city, state, sep = ", "),
         solved = disposition == "Closed by arrest") |>
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
         victim_race %in% c("White", "Black")) |>
  mutate(victim_age = ifelse(victim_age == "Unknown", NA, victim_age)) |>
  mutate(victim_age = as.numeric(victim_age))
```

For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

```{r}
baltimore_df = homicide_df |>
  filter(city_state == "Baltimore, MD")

baltimore_model = glm(solved ~ victim_age + victim_sex + victim_race, 
                       data = baltimore_df, family = "binomial")

tidy_baltimore_model = tidy(baltimore_model)

gender_comparison = tidy_baltimore_model |>
  filter(term == "victim_sexMale")|>
  mutate(or = exp(estimate),
         lower_ci = exp(estimate - 1.96 * std.error),
         upper_ci = exp(estimate + 1.96 * std.error))|>
  knitr::kable()
```

Run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. 

```{r}
city_models = homicide_df |>
  group_by(city_state) |>
  nest() |>
  mutate(model = map(data, ~glm(solved ~ victim_age + victim_sex + victim_race,
                                data = .x, family = "binomial"))) |>
  mutate(tidy_model = map(model, broom::tidy))

or_ci = city_models |>
  mutate(gender_comparison = map(tidy_model, ~.x |>
                                 filter(term == "victim_sexMale") |>
                                 mutate(or = exp(estimate),
                              lower_ci = exp(estimate - 1.96 * std.error),                                   upper_ci = exp(estimate + 1.96 * std.error)))) |>
  select(city_state, gender_comparison) |>
  unnest(gender_comparison)
```

Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

```{r}
ggplot(or_ci, aes(x = reorder(city_state, or), y = or)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) +
  coord_flip() +
  labs(x = "City", y = "Adjusted Odds Ratio", 
       title = "Adjusted Odds Ratios for Solving Homicides: Male vs Female Victims by City") +
  theme_minimal()
```

## Problem 2

Load the data.

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

Fit a simple linear regression with `tmax` as the response with `tmin` and `prcp` as the predictors.

```{r}
lm = lm(tmax ~ tmin + prcp, data = weather_df)
   broom::tidy(lm)
   broom::glance(lm)
```

Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. 

```{r}
res =   
  weather_df |> 
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results = map(models, broom::tidy),
    results2 = map(models, broom::glance)) |> 
  select(results, results2) |> 
  unnest(results2) |> 
  select(r.squared, results) |>
  unnest(results) |>
  select(term, estimate, r.squared) |>
  group_by(term) |>
  mutate(group_id = ceiling((row_number() ))) %>%
  ungroup() |>
  pivot_wider(
    names_from = term,
    values_from = estimate,
  ) |>
  mutate(log_bata = log ( tmin * abs(prcp)))
```

Identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for $\hat{r}^2$ and $log(\hat{\beta_1} * \hat{\beta_2})$.

```{r}
r_squared_ci <- quantile(res$r.squared, c(0.025, 0.975))

log_beta_ci <- quantile(res$log_beta, c(0.025, 0.975))
```

draw the plot.

```{r}
ggplot(res, aes(x = r.squared)) +
  geom_density()+
  labs(x = "Bootstrap R-squared)", y = "Frequency") +
  ggtitle("Distribution of Bootstrap Estimates for r̂²")
```

The goodness of fit of a model can be measured by $\hat{r}^2$.

The plot is slightly left-skewed, with the range appears to be from just below 0.88 to just below 0.95.

The highest frequency of values is around 0.92, which suggests that 0.92 is the most common estimate.

The curve is smooth, which suggests that the bootstrap samples were large enough to provide a good approximation of the distribution.


```{r}
ggplot(res, aes(x = log_bata)) +
  geom_density()+
  labs(x = "Bootstrap Log(Beta1*Beta2)", y = "Frequency") +
  ggtitle("Distribution of Bootstrap Estimates for  Log(Beta1*Beta2)")
```

The logarithm of absolute values was used because $hat{\beta_2}$ was negative, which cannot be directly logged.

A higher value in this range indicates a stronger influence of the two factors. 

The logarithmic values of the distribution range from approximately -9 to -4, indicating a broad spread in the influence of two factors. Most values center around -5, suggesting a moderate influence. The distribution is left-skewed, meaning there's a higher frequency of higher influence values. 